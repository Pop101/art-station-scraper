{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import time\n",
    "import requests\n",
    "import cloudscraper\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pause_report(length, random_delay, count):\n",
    "    pause_time = length*np.random.normal(1,random_delay)\n",
    "    logging.info(f\"Downloaded {count} users. Pausing scraper for {round(pause_time,2)} seconds.\")\n",
    "    time.sleep(pause_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_users(df_art, short_pause = 2, long_pause = 60, random_delay = 0.25):\n",
    "    scraper       = cloudscraper.create_scraper()\n",
    "    users         = dict()\n",
    "    skipped_users = dict()\n",
    "    for _, row in df_art.iterrows():\n",
    "        # Get the user\n",
    "        uname = row['user']['username']\n",
    "        uurl = f\"https://www.artstation.com/users/{uname}.json\"\n",
    "        try:\n",
    "            response = scraper.get(uurl)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            user = response.json()\n",
    "            users[uname] = user\n",
    "            pause_report(short_pause, random_delay, len(users))\n",
    "        except (requests.exceptions.RequestException or requests.exceptions.ConnectionError or AttributeError or TypeError) as e:\n",
    "            logging.debug(\"Cannot establish connection with the following row in df:\")\n",
    "            logging.debug(f\"{uname}:{uurl}\")\n",
    "            logging.debug(\"Skipping to next row\")\n",
    "            skipped_users[uname] = uurl #add key value pair to skipped_urls dict\n",
    "            \n",
    "            if len(skipped_users) % 10 == 0:\n",
    "                logging.warning(\"More than 10 urls have had connection error. Refreshing session and pausing for 5 minutes.\")\n",
    "                logging.warning(len(skipped_users))\n",
    "                pause_report(300, random_delay, len(users)) # pause for 5 minutes if more than 10 urls with connection error\n",
    "                scraper = cloudscraper.create_scraper()\n",
    "        \n",
    "        # take a long pause if 100 users have been downloaded\n",
    "        if len(users) > 0 and len(users)%100 == 0:\n",
    "            pause_report(long_pause, random_delay, len(users))\n",
    "            \n",
    "        # take a long pause x 2 if 500 users have been downloaded\n",
    "        if len(users) > 0 and len(users)%500 == 0:\n",
    "            pause_report(long_pause*2, random_delay, len(users))\n",
    "            \n",
    "            \n",
    "    # Re-try all skipped users\n",
    "    for skipped_uname, uurl in skipped_users.items():\n",
    "        if skipped_uname in users.keys():\n",
    "            continue\n",
    "        \n",
    "        scraper = cloudscraper.create_scraper() # refresh session\n",
    "        try:\n",
    "            response = scraper.get(uurl)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            user = response.json()\n",
    "            users[skipped_uname] = user\n",
    "            pause_report(short_pause, random_delay, len(users))\n",
    "        except (requests.exceptions.RequestException or requests.exceptions.ConnectionError or AttributeError or TypeError) as e:\n",
    "            logging.debug(\"Cannot establish connection with the following row in df:\")\n",
    "            logging.debug(f\"{skipped_uname}:{uurl}\")\n",
    "            logging.debug(\"Skipping to next row\")\n",
    "            logging.debug(e)\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(users).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('query.txt', 'r') as f:\n",
    "    query = f.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df_art = pd.read_json(f\"full_data/query_{query}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape\n",
    "df_users = download_users(df_art, short_pause = 2, long_pause = 60, random_delay = 0.25)\n",
    "df_users.to_csv(f\"full_data/users_{query}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
